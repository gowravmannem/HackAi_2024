{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHnq3VNs5yABgjCFRhMnZo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowravmannem/HackAi_2024/blob/main/Bruteforce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "id": "GdqP5DtpQu_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2GVkBKwL9vH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import r2_score,mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMRegressor\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "df = pd.read_csv('Housing.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "df['mainroad'] = le.fit_transform(df['mainroad'])\n",
        "df['guestroom'] = le.fit_transform(df['guestroom'])\n",
        "df['basement'] = le.fit_transform(df['basement'])\n",
        "df['hotwaterheating'] = le.fit_transform(df['hotwaterheating'])\n",
        "df['airconditioning'] = le.fit_transform(df['airconditioning'])\n",
        "df['prefarea'] = le.fit_transform(df['prefarea'])\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "TXKVDN39MzS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummies = pd.get_dummies(df.furnishingstatus)\n",
        "\n",
        "# Concatenate the dummies to original dataframe\n",
        "merged = pd.concat([df, dummies], axis='columns')\n",
        "\n",
        "# drop the values\n",
        "df_new = merged.drop(columns=['furnishingstatus'])\n",
        "\n",
        "# print the dataframe\n",
        "df_new"
      ],
      "metadata": {
        "id": "qiNeTYtYM3Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# taking out Area data outliers\n",
        "df1 = df_new.copy()\n",
        "\n",
        "#features1 = [i for i in features if i not in ['CHAS','RAD']]\n",
        "features1 = [\"area\"]\n",
        "\n",
        "for i in features1:\n",
        "    Q1 = df1[i].quantile(0.25)\n",
        "    Q3 = df1[i].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    df1 = df1[df1[i] <= (Q3+(1.5*IQR))]\n",
        "    df1 = df1[df1[i] >= (Q1-(1.5*IQR))]\n",
        "    df1 = df1.reset_index(drop=True)\n",
        "df1"
      ],
      "metadata": {
        "id": "UsV_3HEpM5IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df1.drop(['price'],axis=1)\n",
        "y = df1['price']\n"
      ],
      "metadata": {
        "id": "FtLg3epYVMdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def checkVIF(X):\n",
        "    vif = pd.DataFrame()\n",
        "    vif['Features'] = X.columns\n",
        "    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "    vif['VIF'] = round(vif['VIF'], 2)\n",
        "    vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
        "    return(vif)\n",
        "\n",
        "checkVIF(X)"
      ],
      "metadata": {
        "id": "pXVML9PCpH7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#solving multicollinearity issue\n",
        "X=X.drop([\"furnished\",\"semi-furnished\",\"unfurnished\"],axis=1)"
      ],
      "metadata": {
        "id": "2XIjOAL4U8Mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train,X_test,Train_Y,Test_Y = train_test_split(X,y,train_size=0.85, test_size=0.15, random_state=100)"
      ],
      "metadata": {
        "id": "elDD3qlcM7ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#scaler = MinMaxScaler()\n",
        "#standard scaler works better\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "Train_X_std = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "Test_X_std = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
      ],
      "metadata": {
        "id": "jJiIBp5yM-ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model_Evaluation_Comparison_Matrix = pd.DataFrame(np.zeros([5,8]), columns=['Train-R2','Test-R2','Train-RSS','Test-RSS','Train-MSE','Test-MSE','Train-RMSE','Test-RMSE'])\n",
        "rc=np.random.choice(Train_X_std.loc[:,Train_X_std.nunique()>=50].columns.values,1,replace=False)\n",
        "def Evaluate(n, pred1,pred2):\n",
        "    #Plotting predicted predicteds alongside the actual datapoints\n",
        "    plt.figure(figsize=[15,6])\n",
        "    for e,i in enumerate(rc):\n",
        "        plt.subplot(2,3,e+1)\n",
        "        plt.scatter(y=Train_Y, x=Train_X_std[i], label='Actual')\n",
        "        plt.scatter(y=pred1, x=Train_X_std[i], label='Prediction')\n",
        "        plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    #Evaluating the Multiple Linear Regression Model\n",
        "\n",
        "    print('\\n\\n{}Training Set Metrics{}'.format('-'*20, '-'*20))\n",
        "    print('\\nR2-Score on Training set --->',round(r2_score(Train_Y, pred1),20))\n",
        "    print('Mean Squared Error (MSE) on Training set       --->',round(mean_squared_error(Train_Y, pred1),20))\n",
        "    print('Root Mean Squared Error (RMSE) on Training set --->',round(np.sqrt(mean_squared_error(Train_Y, pred1)),20))\n",
        "\n",
        "    print('\\n{}Testing Set Metrics{}'.format('-'*20, '-'*20))\n",
        "    print('\\nR2-Score on Testing set --->',round(r2_score(Test_Y, pred2),20))\n",
        "    print('Mean Squared Error (MSE) on Training set       --->',round(mean_squared_error(Test_Y, pred2),20))\n",
        "    print('Root Mean Squared Error (RMSE) on Training set --->',round(np.sqrt(mean_squared_error(Test_Y, pred2)),20))\n",
        "    print('\\n{}Residual Plots{}'.format('-'*20, '-'*20))\n",
        "\n",
        "    Model_Evaluation_Comparison_Matrix.loc[n,'Train-R2']  = round(r2_score(Train_Y, pred1),20)\n",
        "    Model_Evaluation_Comparison_Matrix.loc[n,'Test-R2']   = round(r2_score(Test_Y, pred2),20)\n",
        "    Model_Evaluation_Comparison_Matrix.loc[n,'Train-MSE'] = round(mean_squared_error(Train_Y, pred1),20)\n",
        "    Model_Evaluation_Comparison_Matrix.loc[n,'Test-MSE']  = round(mean_squared_error(Test_Y, pred2),20)\n",
        "    Model_Evaluation_Comparison_Matrix.loc[n,'Train-RMSE']= round(np.sqrt(mean_squared_error(Train_Y, pred1)),20)\n",
        "    Model_Evaluation_Comparison_Matrix.loc[n,'Test-RMSE'] = round(np.sqrt(mean_squared_error(Test_Y, pred2)),20)\n",
        "\n",
        "    # Plotting y_test and y_pred to understand the spread.\n",
        "    plt.figure(figsize=[15,4])\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    sns.distplot((Train_Y - pred1))\n",
        "    plt.title('Error Terms')\n",
        "    plt.xlabel('Errors')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.scatter(Train_Y,pred1)\n",
        "    plt.plot([Train_Y.min(),Train_Y.max()],[Train_Y.min(),Train_Y.max()], 'r--')\n",
        "    plt.title('Test vs Prediction')\n",
        "    plt.xlabel('y_test')\n",
        "    plt.ylabel('y_pred')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xhCw4eotNBBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RFR = RandomForestRegressor().fit(Train_X_std,Train_Y)\n",
        "pred1 = RFR.predict(Train_X_std)\n",
        "pred2 = RFR.predict(Test_X_std)\n",
        "\n",
        "Evaluate(0, pred1, pred2)"
      ],
      "metadata": {
        "id": "Xcz6ad_KNFOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RLR = Ridge().fit(Train_X_std,Train_Y)\n",
        "pred1 = RLR.predict(Train_X_std)\n",
        "pred2 = RLR.predict(Test_X_std)\n",
        "\n",
        "Evaluate(1, pred1, pred2)"
      ],
      "metadata": {
        "id": "ak8L3aDANJPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LLR = Lasso().fit(Train_X_std,Train_Y)\n",
        "pred1 = LLR.predict(Train_X_std)\n",
        "pred2 = LLR.predict(Test_X_std)\n",
        "\n",
        "Evaluate(2, pred1, pred2)"
      ],
      "metadata": {
        "id": "73F5le-oNJvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENR = ElasticNet().fit(Train_X_std,Train_Y)\n",
        "pred1 = ENR.predict(Train_X_std)\n",
        "pred2 = ENR.predict(Test_X_std)\n",
        "\n",
        "\n",
        "Evaluate(3, pred1, pred2)"
      ],
      "metadata": {
        "id": "UwSyIZmJNL4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "GBR = GradientBoostingRegressor().fit(Train_X_std,Train_Y)\n",
        "pred1 = GBR.predict(Train_X_std)\n",
        "pred2 = GBR.predict(Test_X_std)\n",
        "\n",
        "Evaluate(4, pred1, pred2)"
      ],
      "metadata": {
        "id": "yp6cYGSOOIeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XGB = xgb.XGBRegressor().fit(Train_X_std,Train_Y)\n",
        "pred1 = XGB.predict(Train_X_std)\n",
        "pred2 = XGB.predict(Test_X_std)\n",
        "\n",
        "Evaluate(5, pred1, pred2)"
      ],
      "metadata": {
        "id": "ldVBGcP3PgLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XGRF = xgb.XGBRFRegressor().fit(Train_X_std,Train_Y)\n",
        "pred1 = XGRF.predict(Train_X_std)\n",
        "pred2 = XGRF.predict(Test_X_std)\n",
        "\n",
        "Evaluate(6, pred1, pred2)"
      ],
      "metadata": {
        "id": "MERBp1BgP-8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LGBM = LGBMRegressor().fit(Train_X_std,Train_Y)\n",
        "pred1 = LGBM.predict(Train_X_std)\n",
        "pred2 = LGBM.predict(Test_X_std)\n",
        "\n",
        "Evaluate(7, pred1, pred2)"
      ],
      "metadata": {
        "id": "TbIW7dmIQC_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CBR = CatBoostRegressor().fit(Train_X_std,Train_Y)\n",
        "pred1 = CBR.predict(Train_X_std)\n",
        "pred2 = CBR.predict(Test_X_std)\n",
        "\n",
        "Evaluate(8, pred1, pred2)"
      ],
      "metadata": {
        "id": "mghdhBGqQf7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMC = Model_Evaluation_Comparison_Matrix.copy()\n",
        "EMC.index = ['Random Forest Regressor (RFR)','Ridge Linear Regression (RLR)','Lasso Linear Regression (LLR)','Elastic-Net Regression (ENR)','Gradient Boost Regressor (GBR)','XGB',\"XGRF\",\"LGBM\",\"CBR\"]\n",
        "EMC"
      ],
      "metadata": {
        "id": "NQSr-SUiNOaw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}